# VIBEME.md - Brewdream Project Context

> **Purpose**: High-level context for AI agents. Read this first to understand the project's architecture, patterns, and conventions before making changes. Update this file when making significant architectural changes.
>
> **Related Documents**:
> - [`PRD.md`](./PRD.md) - Product vision, requirements, and acceptance criteria (the "what" and "why")
> - **VIBEME.md** (this file) - Current implementation state, patterns, and conventions (the "how")

## ğŸ¯ Project Mission

**Brewdream** (aka "Realtime AI Video Summit") is a mobile-first microsite for the Livepeer Ã— Daydream Summit during Open Source AI Week. Attendees scan a QR code, create AI-stylized video clips (3-10s) using real-time AI effects, share them on X (Twitter), and receive coffee tickets as rewards.

## ğŸ—ï¸ Tech Stack

- **Frontend**: React 18 + TypeScript + Vite
- **UI**: Tailwind CSS + shadcn/ui component library
- **Backend**: Supabase (PostgreSQL + Edge Functions)
- **Video**: WebRTC (camera) â†’ Daydream AI (effects) â†’ Livepeer (streaming/clipping)
- **Auth**: Supabase Auth with email OTP (magic links)

## ğŸ“ Architecture Overview

```
User Flow:
1. Landing â†’ Login (email OTP) â†’ Capture â†’ ClipView
2. Gallery (home) shows all created clips

Video Pipeline:
Camera â†’ WebRTC â†’ Daydream Stream (AI effects) â†’ Livepeer (HLS playback)
                                                 â†“
                                            Clip creation (3-10s)
                                                 â†“
                                            Share + Coffee Ticket
```

## ğŸ—‚ï¸ Project Structure

```
src/
â”œâ”€â”€ pages/          # Route pages (Capture, ClipView, NotFound, Index)
â”œâ”€â”€ components/     # Reusable components (Gallery, Landing, Login)
â”‚   â””â”€â”€ ui/         # shadcn/ui components (50+ components)
â”œâ”€â”€ integrations/
â”‚   â””â”€â”€ supabase/   # Supabase client & types
â”œâ”€â”€ hooks/          # Custom React hooks (use-mobile, use-toast)
â””â”€â”€ lib/            # Utilities (cn helper, recording, daydream)
    â”œâ”€â”€ recording.ts    # VideoRecorder class, upload/save functions
    â””â”€â”€ daydream.ts     # Daydream stream & WHIP utilities

supabase/
â”œâ”€â”€ functions/      # Edge Functions (API proxy layer)
â”‚   â”œâ”€â”€ daydream-stream/       # Create Daydream AI stream
â”‚   â”œâ”€â”€ daydream-prompt/       # Update stream prompt/effects
â”‚   â”œâ”€â”€ studio-request-upload/ # Request Livepeer upload URL
â”‚   â”œâ”€â”€ studio-asset-status/   # Poll Livepeer asset status
â”‚   â”œâ”€â”€ save-clip/             # Save clip metadata to DB
â”‚   â”œâ”€â”€ generate-ticket/       # Generate coffee QR code
â”‚   â””â”€â”€ send-auth-email/       # Custom OTP email template
â””â”€â”€ migrations/     # Database schema
```

## ğŸ¨ Design System

**Theme**: Dark mode with vibrant gradients
- **Primary**: Purple (`hsl(280 100% 70%)`) - main brand color
- **Accent**: Cyan (`hsl(180 100% 50%)`) - secondary highlights
- **Accent Pink**: (`hsl(330 100% 70%)`) - tertiary accents
- **Background**: Near-black (`hsl(240 10% 3.9%)`)

**Visual Language**:
- Rounded corners (`--radius: 1rem`)
- Glow effects on primary elements (`--shadow-glow`)
- Gradient text for headings (`.gradient-text`)
- Smooth transitions (`--transition-smooth`)
- Square aspect ratios for video (512x512)

**Custom Classes** (defined in `src/index.css`):
- `.gradient-text` - Primary gradient text
- `.glow-primary` - Primary glow effect
- `.glow-strong` - Stronger glow
- `.transition-smooth` - Smooth cubic-bezier transitions

## ğŸ”‘ Key Concepts

### Hard Constraints (from PRD)
These are **non-negotiable** technical requirements:
- âœ… **No client-side API keys** - All Daydream/Livepeer calls via Supabase Edge Functions
- âœ… **WebRTC only** - Force low-latency mode (`lowLatency=force`), no HLS fallback
- âœ… **Browser WHIP publish** - Direct WebRTC to Daydream's `whip_url` (camera + mic)
- âœ… **Clips must be Livepeer Assets** - Use Create Clip API from playbackId
- âœ… **Mobile-first** - Primary target is event attendees on phones
- âœ… **Square aspect ratio** - 512Ã—512 for all video (Daydream pipeline requirement)

### Database Schema
**4 main tables** (see `supabase/migrations/*.sql`, matches PRD data model exactly):
1. **users**: Email, twitter_handle (OTP auth)
2. **sessions**: Links user to stream (stream_id, playback_id, camera_type)
3. **clips**: Video clips with AI metadata (prompt, texture_id, texture_weight, t_index_list, duration_ms)
4. **tickets**: Coffee QR codes (code, redeemed flag)

**RLS Policies**: Public read for clips/sessions, authenticated write, users own their tickets

### Video Processing Flow

1. **Stream Creation** (`daydream-stream`):
   - Pipeline: `pip_SDXL-turbo` (fast AI processing)
   - Returns: `stream_id`, `output_playback_id`, `whip_url`

2. **WebRTC Publishing** (Capture.tsx):
   - Get user media (512x512, front/back camera)
   - Create RTCPeerConnection
   - WHIP protocol to publish to Daydream
   - PiP preview of source, main view shows AI output

3. **Playback Setup** (Capture.tsx):
   - Uses Livepeer Player SDK v4 (`@livepeer/react/player`)
   - Daydream playback IDs require manual src construction (getSrc doesn't recognize them):
     ```typescript
     const src = [
       { src: `https://livepeer.studio/webrtc/${playbackId}`, mime: 'video/h264', type: 'webrtc' },
       { src: `https://livepeer.studio/hls/${playbackId}/index.m3u8`, mime: 'application/vnd.apple.mpegurl', type: 'hls' }
     ];
     ```
   - Front camera mirroring: Stream is mirrored **at the source** using canvas before sending to Daydream
     - Original stream â†’ Canvas with `scaleX(-1)` â†’ `captureStream()` â†’ Mirrored MediaStream
     - Mirrored stream sent to both Daydream and PiP preview
     - Daydream processes mirrored input â†’ Output is naturally mirrored
     - No CSS transforms needed on output (keeps UI elements like loading spinners readable)

4. **AI Effect Controls** (Capture.tsx):
   - **Prompt**: Text description of style
   - **Texture**: Optional image overlay (8 presets)
   - **Creativity** (1-10): Controls denoise strength via `t_index_list`
   - **Quality** (0-1): Number of diffusion steps (0.25=1 step, 1.0=4 steps)
   - **t_index_list**: `[6, 12, 18, 24]` scaled by creativity (formula: `2.62 - 0.132 * creativity`)

5. **Clip Recording** (recording.ts + Capture.tsx):
   - **Button behavior**: Desktop (click toggle), Mobile (press & hold)
   - Button enabled only when video is playing (listens to video events)
   - **Capture**: `videoElement.captureStream()` gets live MediaStream from rendered video
   - **Record**: MediaRecorder with 100ms timeslice collects video chunks
   - **Duration**: 3-10s enforced (auto-stop at 10s, cancel if <3s)
   - **Timer**: Updates every 100ms during recording for smooth counter
   - Records the AI-processed output (not the original camera feed)

6. **Clip Upload** (recording.ts):
   - Request pre-signed upload URL (`studio-request-upload`)
   - PUT blob directly to Livepeer upload URL
   - Poll asset status every 2s (`studio-asset-status`) until ready (max 2min)
   - Returns `assetId`, `playbackId`, `downloadUrl`

7. **Database Save** (recording.ts):
   - Look up session ID from stream
   - Save clip metadata via `save-clip` edge function
   - Includes prompt, texture, creativity/quality params, duration
   - Navigate to clip page

8. **Share & Reward** (ClipView.tsx):
   - Share to X/Twitter with preset text
   - Generate unique coffee ticket code
   - Display ticket as large text + QR data

### Authentication Flow

- **Email OTP** (magic link):
  1. User enters email â†’ `supabase.auth.signInWithOtp()`
  2. Custom email via `send-auth-email` function (Resend)
  3. User enters 6-digit code or clicks magic link
  4. Session stored in localStorage (Supabase client config)

### Routing

```typescript
/ (root)         â†’ Gallery (all clips)
/start          â†’ Landing (marketing page)
/login          â†’ Login (email OTP)
/capture        â†’ Capture (camera + AI controls)
/clip/:id       â†’ ClipView (playback + share + ticket)
```

## ğŸ› ï¸ Development Patterns

### Component Patterns
- **Functional components** with hooks (no class components)
- **shadcn/ui** for all UI primitives (button, input, dialog, etc.)
- **Controlled components** for forms (useState + onChange)
- **useEffect** for side effects (auth check, data loading, debouncing)

### State Management
- **Local state**: `useState` for component state
- **Server state**: Direct Supabase queries (no React Query usage despite being installed)
- **Refs**: For video elements and WebRTC connections

### Naming Conventions
- Components: `PascalCase` (e.g., `Gallery.tsx`)
- Files: `PascalCase` for components, `kebab-case` for utilities
- Functions: `camelCase`
- Constants: `UPPER_SNAKE_CASE` (e.g., `FRONT_PROMPTS`)
- CSS classes: `kebab-case` with Tailwind

### Error Handling
- Try/catch with toast notifications
- Console logging for debugging
- Graceful degradation (loading states, empty states)

### TypeScript Usage
- **Relaxed config** (`strict: false`, `noImplicitAny: false`)
- Types for props, state, and Supabase data
- `any` allowed for quick iteration
- Generated types from Supabase schema (`types.ts`)

## ğŸ”Œ External APIs

### Daydream API
- **Base URL**: `https://api.daydream.live`
- **Endpoints**:
  - `POST /v1/streams` - Create stream
  - `POST /beta/streams/:id/prompts` - Update prompt
- **Auth**: Bearer token (`DAYDREAM_API_KEY`)
- **Key fields**: `pipeline_id`, `prompt`, `texture_weight`, `t_index_list`

### Livepeer Studio API
- **Base URL**: `https://livepeer.studio/api`
- **Endpoints**:
  - `POST /asset/request-upload` - Get pre-signed upload URL
  - `GET /asset/:id` - Check asset status
  - `PUT {uploadUrl}` - Direct upload (from pre-signed URL)
- **Auth**: Bearer token (`LIVEPEER_STUDIO_API_KEY`)
- **Playback**:
  - WebRTC: `https://livepeer.studio/webrtc/{playbackId}`
  - HLS: `https://livepeer.studio/hls/{playbackId}/index.m3u8`
  - **Note**: Daydream playback IDs don't work with `getSrc()` helper, must construct manually

### Supabase Edge Functions
All functions have `verify_jwt: false` (public access)
- CORS enabled for all functions
- Service role key for server operations
- Error responses include hints for debugging

## ğŸ® User Interactions

### Camera Selection (Capture.tsx)
- **Front camera**: Selfie mode, portrait prompts (Ghibli, anime, watercolor)
- **Back camera**: Environment mode, scene prompts (vaporwave, noir, isometric)
- Randomly assigns prompt based on camera type

### Recording Mechanics
- **Desktop**: Click to start, click to stop (toggle mode)
- **Mobile**: Press and hold to record, release to stop
- **Duration**: 3-10s enforced
  - Auto-stop at 10 seconds
  - Cancel if released before 3 seconds (shows toast)
- **Real-time counter**: Updates every 100ms during recording
- **Button states**:
  - Disabled when stream not playing
  - "Starting stream..." when loading
  - "Hold to Brew" / "Tap to Brew" when ready
  - "Recording... (X.Xs)" during capture
- **Enabled only when playing**: Listens to video `playing`/`pause`/`waiting` events
- **Recording technique**:
  - `videoElement.captureStream()` captures rendered video frames from Livepeer Player
  - `MediaRecorder` with 100ms timeslice records to WebM
  - Collects chunks in memory, creates blob on stop
  - Captures AI-processed output (not original camera feed)
  - Recording captures naturally mirrored output (mirroring applied at source, not via CSS)

### Prompt Customization
- **Debounced updates**: 500ms delay on input change
- **Auto-apply**: Changes trigger immediate stream update
- **Texture overlay**: Optional, 8 presets, weight slider (0-1)
- **Creativity/Quality**: Abstract sliders that map to diffusion parameters

## ğŸ¨ Styling Philosophy

### Tailwind First
- Utility classes in JSX (no separate CSS files except index.css)
- `cn()` helper for conditional classes (clsx + tailwind-merge)
- Responsive design with `md:` breakpoints

### Component Styling
- **Cards**: Rounded-3xl borders with subtle glows
- **Buttons**: Rounded-full for CTAs, rounded-md for utilities
- **Inputs**: Rounded-md, border-border, bg-card/background
- **Videos**: Square aspect ratio, rounded-3xl overflow-hidden

### Animations
- `transition-smooth` class for interactions
- Pulse animations for recording state
- Spin for loading states (Loader2 component)
- Scale on hover (1.05) for CTAs

## ğŸ“¦ Dependencies Philosophy

### Installed vs Used
- **React Query**: Installed but not used (direct Supabase calls preferred)
- **shadcn/ui**: ~50 components installed, only ~10 actively used
- **Keep installed**: Allows quick iteration without npm install

### Version Strategy
- Latest stable versions (^X.Y.Z)
- React 18 ecosystem
- TypeScript 5.8+
- Vite 5.4+

## ğŸ” Environment Variables

Required in `.env.local` (Vite):
```
VITE_SUPABASE_URL=https://....supabase.co
VITE_SUPABASE_PUBLISHABLE_KEY=eyJ...
```

Required in Supabase (Edge Functions):
```
DAYDREAM_API_KEY=dd_...
LIVEPEER_STUDIO_API_KEY=...
RESEND_API_KEY=re_...
SEND_EMAIL_HOOK_SECRET=...
SUPABASE_URL=https://...
SUPABASE_SERVICE_ROLE_KEY=...
```

## ğŸš€ Deployment Context

- **Platform**: Lovable.dev (main deployment)
- **Build**: `npm run build` â†’ `dist/`
- **Dev**: `npm run dev` â†’ localhost:8080
- **Preview**: `npm run preview`

## ğŸ§© Code Patterns to Follow

### Adding a New Page
1. Create component in `src/pages/NewPage.tsx`
2. Add route in `src/App.tsx`
3. Use existing UI components from `@/components/ui`
4. Follow dark theme color scheme

### Adding a New API Call
1. Create edge function in `supabase/functions/name/`
2. Add to `supabase/config.toml` with `verify_jwt: false`
3. Call via `supabase.functions.invoke('name', { body: {...} })`
4. Add CORS headers to function

### Updating Database Schema
1. Create migration in `supabase/migrations/`
2. Run `supabase db push` (or apply via Supabase dashboard)
3. Regenerate types: `supabase gen types typescript`
4. Update `src/integrations/supabase/types.ts`

### Adding UI Components
- Use shadcn/ui CLI: `npx shadcn@latest add [component]`
- Components go to `src/components/ui/`
- Import and use with custom classes

### Recording Implementation Pattern
**File**: `src/lib/recording.ts` (VideoRecorder class)

```typescript
// 1. Create recorder from video element
const recorder = new VideoRecorder(videoElement);

// 2. Start recording (captures MediaStream)
await recorder.start();

// 3. Stop recording (returns blob + duration)
const { blob, durationMs } = await recorder.stop();

// 4. Upload to Livepeer (3-step process)
const { assetId, playbackId, downloadUrl } = await uploadToLivepeer(blob, filename);
// - Requests pre-signed upload URL
// - PUTs blob directly to URL
// - Polls asset status until ready

// 5. Save to database
const clip = await saveClipToDatabase({ assetId, playbackId, ... });
```

**Key implementation notes**:
- `captureStream()` must be called on the actual `<video>` DOM element (not iframe)
- Front camera mirroring: Canvas-based stream manipulation before sending to Daydream
  ```typescript
  // Mirror at source (in startWebRTCPublish)
  const mirrorStream = (originalStream: MediaStream): MediaStream => {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;
    ctx.scale(-1, 1); // Mirror horizontally
    ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
    return canvas.captureStream(30); // + audio tracks
  };
  ```
- Recording is of AI-processed output, not original camera feed
- WebM format with 100ms timeslice for smooth capture
- Maximum 2-minute polling for asset processing

## ğŸ¯ Key Business Logic

### T-Index Calculation (Creativity/Quality)
**Matches PRD Â§ "Controls â†’ parameter mapping"**

```typescript
// Quality [0..1] determines number of diffusion steps (defaults to 0.4)
quality < 0.25 â†’ [6]              (1 step, fastest)
quality < 0.50 â†’ [6, 12]          (2 steps)
quality < 0.75 â†’ [6, 12, 18]      (3 steps)
quality â‰¥ 0.75 â†’ [6, 12, 18, 24]  (4 steps, best quality)

// Creativity [1..10] scales the indices (defaults to 5)
// Higher creativity â†’ lower indices â†’ more stylization
scale = 2.62 - 0.132 * creativity
t_index = base_index * scale (clamped 0-50, rounded)

// Rationale (from PRD):
// - Higher/later indices bias refinement
// - Earlier indices increase stylization
// - Fallback: [4, 12, 20] if any value invalid
```

### Clip Duration Enforcement
- UI: 3-10s range enforced by hold button
- Database: CHECK constraint (3000-10000 ms)
- Backend: Clamping in `stopRecording()`

### Ticket Generation
- Format: Random base36 string (8 chars, uppercase)
- QR Data: `DD-COFFEE-{code}`
- One ticket per session (users table relation)

## ğŸ”„ State Flow Examples

### Capture Flow State
```
Initial: cameraType=null (camera selection screen)
  â†“ selectCamera('front'|'back')
Loading: initializing stream
  â†“ startWebRTCPublish()
Ready: playbackId set, showing AI output
  â†“ startRecording() (hold button)
Recording: recordStartTime set, counter running
  â†“ stopRecording() (release button)
Processing: creating clip via Livepeer
  â†“ navigate to /clip/:id
```

### Prompt Update Flow
```
User types â†’ setState â†’ useEffect (500ms debounce) â†’ updatePrompt()
                                                      â†“
                                    supabase.functions.invoke('daydream-prompt')
                                                      â†“
                                          Daydream API updates stream
                                                      â†“
                                              Video effect changes
```

## ğŸ¨ UI/UX Patterns

### Loading States
- **Spinner**: `<Loader2 className="animate-spin" />` for async operations
- **Skeleton**: Pulse animation for loading content
- **Disabled buttons**: During loading with loader icon

### Empty States
- Gallery: "No clips yet" with CTA button
- Clear messaging with next action

### Error Handling
- Toast notifications (bottom-right)
- Destructive variant for errors
- Console logging for debugging

### Responsive Design
- Mobile-first approach
- `md:` breakpoints for desktop enhancements
- Touch-friendly targets (min 44px)

## ğŸ”§ Common Operations

### Reading Supabase Data
```typescript
const { data, error } = await supabase
  .from('table_name')
  .select('*')
  .eq('id', id)
  .single();
```

### Calling Edge Functions
```typescript
const { data, error } = await supabase.functions.invoke('function-name', {
  body: { key: 'value' }
});
```

### Toast Notifications
```typescript
toast({
  title: 'Success!',
  description: 'Operation completed',
  variant: 'destructive' // optional, for errors
});
```

### Navigation
```typescript
// Declarative
<Link to="/path">Link</Link>

// Programmatic
navigate('/path');
```

## ğŸš¨ Critical Constraints

1. **Video Resolution**: 512x512 (square) - hardcoded for Daydream pipeline
2. **Clip Duration**: 3-10 seconds (UI + DB constraints)
3. **Camera Types**: Only 'front' | 'back' (no custom options)
4. **Public Access**: All RLS policies allow public reads for clips/sessions
5. **No Auth Required**: Edge functions have `verify_jwt: false` for simplicity
6. **Single Stream**: User can only have one active stream at a time
7. **Browser Recording**: Requires `captureStream()` support (Chrome/Edge/Firefox/Safari modern versions)
8. **Video Element Access**: Must use Livepeer Player component (not iframe) for recording

## ğŸ› Known Issues & Workarounds

### Camera Mirroring (âœ… RESOLVED)
**Solution**: Mirror the MediaStream **at the source** before sending to Daydream:
- Original camera stream â†’ Canvas with `scaleX(-1)` â†’ `captureStream(30)` â†’ Mirrored MediaStream
- Mirrored stream sent to Daydream via WHIP
- Daydream processes already-mirrored input
- Output is naturally mirrored (no CSS transforms needed)
- **Benefits**:
  - Loading spinners and text remain readable (not flipped)
  - Recording captures correctly mirrored video
  - Works consistently across all browsers

### Daydream Playback IDs Not Recognized
**Issue**: `getSrc()` from `@livepeer/react/external` returns `null` for Daydream playback IDs.

**Workaround**: Manually construct src array with WebRTC and HLS URLs:
```typescript
const src = [
  { src: `https://livepeer.studio/webrtc/${playbackId}`, mime: 'video/h264', type: 'webrtc' },
  { src: `https://livepeer.studio/hls/${playbackId}/index.m3u8`, mime: 'application/vnd.apple.mpegurl', type: 'hls' }
];
```

### Video `object-fit: cover` Issues
**Issue**: Getting video to properly fill square container with `object-fit: cover` proved challenging with complex CSS/player interactions.

**Status**: Resolved by peer. May require specific CSS targeting of Livepeer Player internal elements.

## ğŸ“ Coding Conventions

### TypeScript
- Types are **guides, not gates** (strict mode disabled)
- Use `any` for quick iteration, refine later if needed
- Interface for component props, type for data models
- Generated types from Supabase are source of truth

### React Patterns
- Functional components only (no classes)
- Hooks for state and effects
- Avoid premature optimization
- Keep components flat (minimal nesting)

### File Organization
- One component per file
- Co-locate related utilities
- Index exports for public APIs
- Keep shadcn/ui components unmodified

### CSS
- Tailwind utilities inline
- CSS variables for design tokens
- Avoid custom CSS files
- Use `cn()` for conditional classes

## ğŸ”„ Update Triggers

**When to update VIBEME.md**:
- [ ] New major features (e.g., add recording playback)
- [ ] Architecture changes (e.g., add state management library)
- [ ] New API integrations (e.g., add payment system)
- [ ] Database schema changes (new tables/fields)
- [ ] Design system updates (new colors, patterns)
- [ ] Workflow changes (new user flows)

**Do NOT update for**:
- Minor bug fixes
- Copy/text changes
- Individual component updates
- CSS tweaks
- Dependency version bumps

## ğŸ¯ Agent Guidance

### When receiving high-level prompts:

1. **Read VIBEME.md first** for context
2. **Check existing patterns** before inventing new ones
3. **Reuse UI components** from shadcn/ui library
4. **Follow dark theme** with purple/cyan accents
5. **Use Supabase** for all backend operations
6. **Add error handling** with toast notifications
7. **Test with TypeScript** (but don't let types block you)
8. **Update VIBEME.md** if you make architectural changes

### Common Agent Tasks:

**"Add a new field to clips"**:
â†’ Update migration â†’ Regenerate types â†’ Update ClipView/Capture â†’ Update VIBEME

**"Change the UI of X"**:
â†’ Check design system colors â†’ Use existing shadcn components â†’ Follow responsive patterns

**"Add analytics"**:
â†’ Create new edge function â†’ Update relevant pages â†’ Add to supabase config

**"Fix video not loading"**:
â†’ Check WebRTC flow â†’ Verify API keys â†’ Check CORS â†’ Look at console logs

## ğŸŒŸ Project Vibe

This is a **fast-moving event app** - prioritize:
- âœ… **Working over perfect**: Ship features quickly
- âœ… **Visual polish**: Users see gradients and glows everywhere
- âœ… **Clear feedback**: Loading states, toasts, error messages
- âœ… **Mobile-first**: Summit attendees use phones
- âœ… **Fun UX**: Playful interactions, smooth animations

Avoid:
- âŒ Over-engineering (no complex state management)
- âŒ Premature optimization (readability > performance)
- âŒ Extensive validation (trust the user, handle errors gracefully)
- âŒ Long forms (keep interactions quick and simple)

## ğŸ“š Reference Quick Links

- **Daydream Docs**: Pipeline configs, prompt formats, texture handling
- **Livepeer Docs**: Clip API, asset statuses, playback URLs
- **Supabase Docs**: RLS policies, edge function patterns, auth flows
- **shadcn/ui Docs**: Component APIs, styling patterns

## ğŸ”— VIBEME â†” PRD Cross-Reference

**How to use these documents together:**
- **PRD.md** = Product vision, requirements, acceptance criteria â†’ Read for "what to build"
- **VIBEME.md** = Current state, patterns, conventions â†’ Read for "how it's built"

**Section mapping:**

| VIBEME Section | PRD Section | Notes |
|----------------|-------------|-------|
| Hard Constraints | "Hard constraints" | Technical non-negotiables |
| Database Schema | "Data model (Supabase Postgres)" | Exact table structure match |
| T-Index Calculation | "Controls â†’ parameter mapping" | Algorithm implementation |
| Video Processing Flow | "Daydream / playback / clipping" | WHIP, WebRTC, clip creation |
| Routing | "Screens & components" | Page structure |
| Camera Selection | "Defaults (front/back)" | Prompt selection logic |
| External APIs | "Edge Functions (Supabase)" | API proxy patterns |
| Acceptance Criteria | "Acceptance criteria" | Feature checklist |
| Red-team notes | "Red-team notes" | Known edge cases |

**When PRD and VIBEME diverge:**
1. PRD describes the **intended design** (source of truth for features)
2. VIBEME describes **current implementation** (source of truth for code patterns)
3. If implemented differently than PRD, note it in VIBEME with rationale
4. Update both docs when making architectural changes

## ğŸ“‹ Implementation Status vs PRD

**Fully implemented (âœ…):**
- Email OTP auth (no X OAuth as per PRD optional clause)
- Camera selector (front/back) with permission prompts
- Live output (1:1 square) with PiP source preview via Livepeer Player SDK v4
- Manual src construction for Daydream playback IDs
- Prompt, Texture+Weight, Creativity, Quality controls with debounced updates
- Recording with `captureStream()` + `MediaRecorder` (3-10s duration enforcement)
- Desktop (click toggle) vs Mobile (press & hold) recording mechanics
- Real-time recording counter (100ms updates)
- Auto-stop at 10s, cancel if <3s
- Front camera mirroring at source (canvas-based stream manipulation before Daydream)
- Recording button enabled only when video is playing
- Three-step upload to Livepeer Studio (request URL â†’ PUT blob â†’ poll status)
- Clip metadata saved to database with all AI parameters
- Share to X with default copy
- Coffee QR display and DB storage
- Gallery home with square grid

**Partially implemented (âš ï¸):**
- Texture system: 8 slots defined, but actual texture images are placeholders
- Ticket email: Function exists but may not be fully wired up
- Clip page: Shows video but QR visibility logic may need refinement

**Not yet implemented (âŒ):**
- `/ticket/:code` dedicated route (ticket only shows on clip page)
- Actual QR code rendering (shows code text, not QR image)
- Email delivery of ticket (function exists but integration TBD)

**Deviations from PRD (ğŸ“):**
- **Recording method**: Browser-side `captureStream()` + `MediaRecorder` instead of Livepeer Create Clip API
  - **Rationale**: More reliable across network conditions, captures exact rendered frames, works with WebRTC-only playback
  - **Trade-off**: Requires browser support for captureStream (widely supported in modern browsers)
- **Playback src**: Manual src construction instead of using `getSrc()` helper
  - **Rationale**: Daydream playback IDs not recognized by Livepeer's `getSrc()` utility
- **Recording mechanics**: Different behavior for desktop vs mobile
  - **Rationale**: Better UX - desktop users can multitask, mobile users get familiar "hold to record" pattern
- **Camera mirroring**: Canvas-based stream manipulation before Daydream instead of CSS transforms
  - **Rationale**: Ensures Daydream processes mirrored input, output is naturally mirrored, UI elements remain readable
  - **Benefit**: More robust, no CSS transform issues, consistent across browsers
- **Gallery**: Shows video player instead of thumbnails (simpler, works for POC)
- **No X OAuth**: Per PRD optional clause ("optional if trivial; otherwise require email")
- **Ticket route**: Simplified (QR shown on clip page only)

---

**Last Updated**: 2025-10-10 (Canvas-based mirroring at source for natural selfie mode)
**Project Status**: Active development for Livepeer Ã— Daydream Summit (Brewdream)
**Maintainer Note**: Keep this file concise but comprehensive. Every section should answer "what do I need to know to work on this?" Always check PRD for feature requirements before implementing.

